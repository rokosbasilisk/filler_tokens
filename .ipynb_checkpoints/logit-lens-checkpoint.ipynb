{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo:\n",
    "# - understand how the training data text is represented for chain of thought ot 3SUM sequences\n",
    "# - function for evaluating accuracy\n",
    "# - understand decoder implementation\n",
    "# - function to print rank-n for layer m and then iterate over using this\n",
    "\n",
    "\n",
    "# experiments:\n",
    "# - write the claims of the paper: COT is uninterpretable as it can be hidden, but this hidden COT still increases performs\n",
    "# - see where it is being replaced with '.' and where it is just the numbers\n",
    "# - check this across layer, across rank\n",
    "# - is this gradual or not gradual?\n",
    "# - check if these decoded sequences from different ranks and layers are in anyway simialr to the actual trianing dataset.\n",
    "# - write the punchline: you only see the decoded text of COT, but not what is there in the rest of the logits as information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.match3 import *\n",
    "from src.utils import InputEmbedCausalTransformer\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import Levenshtein\n",
    "import json\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/home/loki/projects/filler_tokens/output_dir/2024-08-14-22-matchdata-checkpoint-final/model_weights.pt\"\n",
    "CONFIG_FILE = \"/home/loki/projects/filler_tokens/misc/llama_d384l4h6.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/matchdata_trainset_2024-08-13.csv', header=None, names=[\"text\"])\n",
    "test_df = pd.read_csv('data/matchdata_testset_2024-08-13.csv', header=None, names=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate encodings\n",
      "raw input 0  339 234 230 125 222 811 686 534 369 258 P 1- 5 2- 6 3- 4 4- 5 0- 1 0- 9 0- 8 0- 9 0- 8 1- 6 1- 9 4- 6 5- 4 6- 8 1- 7 1- 9 1- 4 3- 5 4- 2 2- 0 2- 6 7- 4 2- 9 9- 8 4- 7 3- 9 6- 7 7- 6 3- 4 3- 7 5- 3 4- 0 4- 7 4- 1 4- 4 6- 9 7- 3 5- 0 9- 0 7- 1 8- 9 6- 8 8- 8 9- 8 8- 1 9- 1 A False\n",
      "encoded sample 0 {'input_ids': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    6,   30,\n",
      "           7,   31,    8,   29,    9,   30,    5,   26,    5,   34,    5,   33,\n",
      "           5,   34,    5,   33,    6,   31,    6,   34,    9,   31,   10,   29,\n",
      "          11,   33,    6,   32,    6,   34,    6,   29,    8,   30,    9,   27,\n",
      "           7,   25,    7,   31,   12,   29,    7,   34,   14,   33,    9,   32,\n",
      "           8,   34,   11,   32,   12,   31,    8,   29,    8,   32,   10,   28,\n",
      "           9,   25,    9,   32,    9,   26,    9,   29,   11,   34,   12,   28,\n",
      "          10,   25,   14,   25,   12,   26,   13,   34,   11,   33,   13,   33,\n",
      "          14,   33,   13,   26,   14,   26,    4,    2,    0, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100])}\n"
     ]
    }
   ],
   "source": [
    "train_set = Match3VectorDataset(train_df, 3, 10, 10, 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate encodings\n",
      "raw input 0  433 450 421 129 107 924 489 711 540 034 P 0- 3 0- 4 3- 2 4- 0 5- 5 0- 8 7- 1 0- 7 9- 4 1- 8 3- 5 1- 7 1- 3 6- 8 1- 1 8- 9 9- 4 3- 5 4- 2 5- 5 6- 8 2- 2 2- 6 9- 5 3- 2 5- 0 6- 5 3- 0 8- 9 9- 5 4- 2 6- 8 7- 1 8- 4 4- 3 6- 3 5- 6 8- 4 9- 8 7- 9 8- 9 6- 1 7- 2 7- 7 9- 7 9- 5 A False\n",
      "encoded sample 0 {'input_ids': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    5,   28,\n",
      "           5,   29,    8,   27,    9,   25,   10,   30,    5,   33,   12,   26,\n",
      "           5,   32,   14,   29,    6,   33,    8,   30,    6,   32,    6,   28,\n",
      "          11,   33,    6,   26,   13,   34,   14,   29,    8,   30,    9,   27,\n",
      "          10,   30,   11,   33,    7,   27,    7,   31,   14,   30,    8,   27,\n",
      "          10,   25,   11,   30,    8,   25,   13,   34,   14,   30,    9,   27,\n",
      "          11,   33,   12,   26,   13,   29,    9,   28,   11,   28,   10,   31,\n",
      "          13,   29,   14,   33,   12,   34,   13,   34,   11,   26,   12,   27,\n",
      "          12,   32,   14,   32,   14,   30,    4,    2,    0, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100])}\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "test_set = Match3VectorDataset(test_df, 3, 10, 10, 'P')\n",
    "print(test_set.input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.tensorize_inputs_worker(pd.Series({\"text\":test_df.iloc[-1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_input_tensors(input_string):\n",
    "    return {\"input_ids\":test_set.tensorize_inputs_worker({\"text\":pd.Series([input_string], index=['text'], name='1999')}).squeeze()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_input_tensors(\"1 P A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_label_tensors(input_string):\n",
    "    return {\"labels\":test_set.tensorize_labels_worker({\"text\":pd.Series([input_string], index=['text'], name='1999')})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float16)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_input_tensors(\"100 P A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block, unembed_matrix, norm):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.unembed_matrix = unembed_matrix\n",
    "        self.norm = norm\n",
    "        self.block_output_unembedded = None\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = self.block(*args, **kwargs)\n",
    "        if isinstance(output, tuple):\n",
    "            self.block_output_unembedded = self.unembed_matrix(self.norm(output[0]))\n",
    "            return output\n",
    "        else:\n",
    "            self.block_output_unembedded = self.unembed_matrix(self.norm(output))\n",
    "            return output\n",
    "\n",
    "    def reset_block_output(self):\n",
    "        self.block_output_unembedded = None\n",
    "\n",
    "class LlamaHelper:\n",
    "    def __init__(self, config_file, model_path, test_set):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        config = AutoConfig.from_pretrained(config_file)\n",
    "        model = InputEmbedCausalTransformer(AutoModelForCausalLM.from_config(config), test_set.input_dim)\n",
    "        state_dict = torch.load(model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model = model.to(self.device)\n",
    "        self.model = model\n",
    "        self.word_index_map = test_set.word_index_map\n",
    "        self.data_len = test_set.data_len\n",
    "        self.mod = test_set.mod\n",
    "        self.input_dim = test_set.input_dim\n",
    "        \n",
    "        for i, layer in enumerate(self.model.base_model.model.layers):\n",
    "            self.model.base_model.model.layers[i] = BlockOutputWrapper(layer, self.model.base_model.lm_head, self.model.base_model.model.norm)\n",
    "\n",
    "    def decode_tensors(self, sequence):\n",
    "        decoded_sequence = []\n",
    "        marker_found = False\n",
    "\n",
    "        for token in sequence:\n",
    "            token = token.item()\n",
    "            if token == -100:\n",
    "                if not marker_found:\n",
    "                    decoded_sequence.append(\"[MASK]\")\n",
    "                continue\n",
    "            elif token == 0:\n",
    "                decoded_sequence.append(\"[EOS]\")\n",
    "                break  # Stop decoding after EOS\n",
    "            elif token < len(self.word_index_map):\n",
    "                # Regular word\n",
    "                word = list(self.word_index_map.keys())[list(self.word_index_map.values()).index(token)]\n",
    "                decoded_sequence.append(word)\n",
    "                if word in [\"A\", \"P\"]:\n",
    "                    marker_found = True\n",
    "            else:\n",
    "                # Handle digit labels\n",
    "                offset = len(self.word_index_map)\n",
    "                if token < offset + self.data_len * 2:\n",
    "                    # Tuple index encoding\n",
    "                    idx = (token - offset) % self.data_len\n",
    "                    tuple_pos = (token - offset) // self.data_len\n",
    "                    decoded_sequence.append(f\"{tuple_pos}-{idx}\")\n",
    "                else:\n",
    "                    # Single digit or digit in tuple\n",
    "                    char_pos = (token - offset - self.data_len * 2) // self.mod\n",
    "                    digit = (token - offset - self.data_len * 2) % self.mod\n",
    "                    if char_pos == 0 or len(decoded_sequence) == 0 or not decoded_sequence[-1][-1].isdigit():\n",
    "                        decoded_sequence.append(str(digit))\n",
    "                    else:\n",
    "                        decoded_sequence[-1] += str(digit)\n",
    "\n",
    "        return \" \".join(decoded_sequence)\n",
    "\n",
    "\n",
    "    def set_add_attn_output(self, layer, add_output):\n",
    "        self.model.base_model.model.layers[layer].attn_add_tensor(add_output)\n",
    "\n",
    "    def get_attn_activations(self, layer):\n",
    "        return self.model.base_model.model.layers[layer].get_attn_activations()\n",
    "\n",
    "    def reset_all_layers(self):\n",
    "        for layer in self.model.base_model.model.layers:\n",
    "            layer.reset_block_output()\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_tokens(model, layer_idx, input_ids, decode_tensors, num_layers, rank=1, device=\"cuda\", skip_idx=None):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids.float().unsqueeze(0))\n",
    "            logits = outputs.logits\n",
    "\n",
    "        last_token_logits = logits[0, -1, :]\n",
    "\n",
    "        if layer_idx < num_layers:\n",
    "            layer = model.base_model.model.layers[layer_idx]\n",
    "            if layer.block_output_unembedded is not None:\n",
    "                last_token_logits = layer.block_output_unembedded[0, -1, :]\n",
    "\n",
    "        # Get top k values and indices, where k is rank + 1 (to account for potential skip)\n",
    "        k = rank + 1\n",
    "        val, idx = torch.topk(last_token_logits, k)\n",
    "\n",
    "        # If skip_idx is provided, remove it from consideration\n",
    "        if skip_idx is not None:\n",
    "            mask = idx != skip_idx\n",
    "            idx = idx[mask]\n",
    "            val = val[mask]\n",
    "\n",
    "        # Select the token at the specified rank (subtracting 1 because rank is 1-indexed)\n",
    "        selected_idx = min(rank - 1, len(idx) - 1)\n",
    "\n",
    "        token = decode_tensors(idx[selected_idx].unsqueeze(-1)).strip()\n",
    "\n",
    "        return token, idx[selected_idx].item()\n",
    "\n",
    "\n",
    "    def create_new_token_input(self, token_id):\n",
    "        new_input = torch.zeros(1, self.input_dim, dtype=torch.float16)\n",
    "        if token_id < len(self.word_index_map):\n",
    "            new_input[0, token_id] = 1\n",
    "        else:\n",
    "            # Handle digit sequences\n",
    "            offset = len(self.word_index_map)\n",
    "            if token_id < offset + self.data_len * 2:\n",
    "                # Tuple index encoding\n",
    "                idx = (token_id - offset) % self.data_len\n",
    "                tuple_pos = (token_id - offset) // self.data_len\n",
    "                new_input[0, offset + tuple_pos * self.data_len + idx] = 1\n",
    "            else:\n",
    "                # Single digit or digit in tuple\n",
    "                char_pos = (token_id - offset - self.data_len * 2) // self.mod\n",
    "                digit = (token_id - offset - self.data_len * 2) % self.mod\n",
    "                new_input[0, offset + self.data_len * 2 + char_pos * self.mod + digit] = 1\n",
    "        return new_input\n",
    "    \n",
    "\n",
    "    def print_logit_progression(self, inputs,\n",
    "                                max_new_tokens=len(test_set[0]['labels']),\n",
    "                                layer_number=None,\n",
    "                                rank=1,\n",
    "                                skip_idx = None,\n",
    "                                input_length = None):\n",
    "        \n",
    "\n",
    "        self.reset_all_layers()\n",
    "        num_layers = len(self.model.base_model.model.layers)\n",
    "        result_dict = {f\"h{i}_out\": [] for i in range(num_layers)}\n",
    "        result_dict[\"h_out\"] = []\n",
    "        input_ids = inputs['input_ids'].to(self.device)\n",
    "        if input_length:\n",
    "            input_ids = input_ids[:input_length]\n",
    "        generated_sequence = input_ids.clone()\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            self.reset_all_layers()\n",
    "            \n",
    "            if layer_number is not None:\n",
    "                if layer_number > num_layers:\n",
    "                    print(f\"Error: Layer number {layer_number} is out of range. Max layer is {num_layers}.\")\n",
    "                    return {}\n",
    "                token, token_id = self.get_tokens(self.model, layer_number, generated_sequence, self.decode_tensors, num_layers, rank, self.device, skip_idx)\n",
    "                layer_name = f\"h{layer_number}_out\" if layer_number < num_layers else \"h_out\"\n",
    "                result_dict[layer_name].append(token)\n",
    "            else:\n",
    "                for i in range(num_layers + 1):\n",
    "                    token, token_id = self.get_tokens(self.model, i, generated_sequence, self.decode_tensors, num_layers, rank, self.device, skip_idx)\n",
    "                    layer_name = f\"h{i}_out\" if i < num_layers else \"h_out\"\n",
    "                    result_dict[layer_name].append(token)\n",
    "                    \n",
    "            if token in [\"[EOS]\",\"True\",\"False\"]: break\n",
    "\n",
    "            try:\n",
    "                new_token_input = self.create_new_token_input(token_id).to(self.device)\n",
    "                    \n",
    "                generated_sequence = torch.cat([generated_sequence, new_token_input], dim=0)\n",
    "            except:\n",
    "                generated_sequence = torch.cat([generated_sequence], dim=0)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Print results\n",
    "        if layer_number is not None:\n",
    "            layer_name = f\"h{layer_number}_out\" if layer_number < num_layers else \"h_out\"\n",
    "            print(f\"{rank}th highest logit for {layer_name}:\")\n",
    "            print(\" \".join(result_dict[layer_name]))\n",
    "        else:\n",
    "            print(f\"{rank}th highest logit:\")\n",
    "            for layer_name, tokens in result_dict.items():\n",
    "                print(f\"{layer_name:<5}: \" + \" \".join(tokens))\n",
    "\n",
    "        return result_dict\n",
    "    \n",
    "    def get_layer_logits(self, inputs, layer_idx):\n",
    "        self.reset_all_layers()\n",
    "        num_layers = len(self.model.base_model.model.layers)\n",
    "        \n",
    "        if layer_idx > num_layers:\n",
    "            raise ValueError(f\"Error: Layer number {layer_idx} is out of range. Max layer is {num_layers}.\")\n",
    "        \n",
    "        input_ids = inputs['input_ids'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids.float().unsqueeze(0))\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        if layer_idx < num_layers:\n",
    "            layer = self.model.base_model.model.layers[layer_idx]\n",
    "            if layer.block_output_unembedded is not None:\n",
    "                logits = layer.block_output_unembedded\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 384, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x BlockOutputWrapper(\n",
       "        (block): LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (o_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (up_proj): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (down_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "        (unembed_matrix): Linear(in_features=384, out_features=32000, bias=False)\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlamaHelper(CONFIG_FILE, MODEL_PATH, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/400 [00:00<03:59,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 3 0-2 1 0-0 9 0-4 6 0-5 8 0-6 9 0-7 9 0-0 4 0-9 7 0-2 9 0-3 0 0-1 6 0-5 8 0-6 6 0-7 4 0-8 9 0-9 2 0-3 1 0-2 6 0-5 6 0-6 9 0-2 2 0-2 7 0-9 0 0-4 0 0-5 0 0-6 8 0-3 7 0-8 3 0-9 5 0-4 5 0-6 3 0-7 5 0-4 2 0-4 3 0-6 3 0-5 3 0-8 4 0-5 1 0-6 8 0-6 6 0-6 6 0-7 3 0-9 3 0-8 6 0-9 1 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/400 [00:01<03:58,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 5 0-2 1 0-3 3 0-4 6 0-0 0 0-0 7 0-0 6 0-8 0-9 0-9 3 0-2 6 0-3 9 0-4 1 0-1 8 0-1 2 0-1 1 0-1 5 0-1 9 0-2 5 0-2 3 0-2 9 0-2 4 0-7 5 0-2 9 0-9 3 0-4 4 0-5 7 0-3 2 0-3 3 0-3 8 0-9 2 0-5 5 0-6 1 0-4 1 0-4 0 0-9 4 0-5 4 0-5 0 0-5 6 0-5 5 0-6 1 0-6 5 0-9 6 0-7 7 0-7 1 0-9 8 0-9 2 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/400 [00:01<03:58,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 5 0-0 8 0-0 7 0-0 0 0-0 2 0-0 0 0-0 9 0-0 7 0-9 2 0-1 5 0-1 6 0-1 7 0-1 3 0-6 6 0-1 5 0-1 1 0-1 6 0-3 2 0-2 0 0-5 5 0-6 9 0-2 9 0-2 5 0-9 2 0-4 9 0-3 7 0-3 6 0-3 5 0-8 6 0-9 6 0-4 2 0-6 9 0-4 1 0-4 7 0-4 4 0-5 3 0-5 7 0-8 8 0-9 8 0-7 3 0-8 6 0-9 9 0-8 3 0-9 3 0-8 9 0-9 9 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/400 [00:02<03:58,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 9 0-2 6 0-3 6 0-0 2 0-5 1 0-0 1 0-7 9 0-0 1 0-9 4 0-2 5 0-1 5 0-4 0 0-1 0 0-1 2 0-7 8 0-1 2 0-1 2 0-2 1 0-2 5 0-5 1 0-2 1 0-2 9 0-2 9 0-9 4 0-4 7 0-5 7 0-3 9 0-3 8 0-8 6 0-9 9 0-5 0 0-6 2 0-7 9 0-4 1 0-4 9 0-5 0 0-5 6 0-5 7 0-5 5 0-7 4 0-6 8 0-9 2 0-8 2 0-9 1 0-9 6 0-9 9 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 5/400 [00:03<03:57,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 0 0-2 2 0-0 9 0-0 0 0-0 9 0-0 7 0-7 1 0-0 8 0-9 8 0-2 0 0-1 8 0-4 2 0-5 1 0-1 9 0-7 8 0-8 5 0-9 3 0-3 1 0-2 5 0-2 4 0-2 5 0-2 1 0-2 0 0-9 8 0-4 8 0-3 9 0-3 3 0-7 6 0-3 3 0-3 1 0-4 1 0-6 9 0-7 8 0-4 9 0-4 9 0-6 6 0-5 7 0-5 6 0-5 4 0-6 5 0-6 7 0-9 9 0-7 1 0-9 8 0-9 7 0-9 7 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/400 [00:03<03:56,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 0-9 0-2 7 0-0 7 0-4 8 0-5 4 0-0 7 0-7 6 0-8 5 0-9 8 0-2 1 0-1 9 0-4 1 0-1 6 0-1 6 0-1 9 0-8 8 0-9 5 0-3 6 0-2 0 0-5 1 0-2 2 0-7 3 0-2 4 0-9 5 0-4 6 0-5 9 0-3 6 0-7 4 0-8 1 0-9 5 0-5 7 0-6 1 0-4 6 0-4 4 0-4 2 0-5 1 0-5 5 0-5 1 0-5 2 0-6 1 0-6 4 0-6 5 0-8 3 0-7 4 0-9 3 0-9 3 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/400 [00:04<03:55,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 1 0-0 2 0-0 5 0-0 5 0-0 9 0-6 9 0-7 9 0-8 7 0-0 6 0-2 1 0-1 9 0-4 2 0-1 6 0-1 8 0-7 3 0-1 6 0-9 3 0-3 3 0-2 6 0-2 4 0-6 8 0-7 7 0-8 7 0-9 4 0-4 4 0-3 9 0-6 9 0-7 5 0-3 5 0-9 7 0-4 3 0-6 8 0-7 2 0-4 6 0-4 6 0-5 1 0-5 6 0-5 4 0-5 6 0-6 0 0-6 4 0-6 1 0-7 8 0-9 4 0-9 9 0-9 9 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/400 [00:04<03:54,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 7 0-2 5 0-3 3 0-0 7 0-5 4 0-0 6 0-7 3 0-8 3 0-0 4 0-1 8 0-3 5 0-4 4 0-1 7 0-6 5 0-1 4 0-8 6 0-1 3 0-3 2 0-2 5 0-5 0-7 0-2 1 0-7 0 0-8 4 0-9 5 0-4 7 0-3 6 0-6 1 0-3 2 0-3 3 0-9 0 0-4 5 0-6 0-8 0-4 5 0-4 9 0-4 2 0-6 6 0-7 0 0-8 4 0-5 0 0-6 1 0-6 5 0-6 2 0-8 2 0-9 3 0-8 9 0-9 1 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/400 [00:05<03:53,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 2 0-2 3 0-0 6 0-4 0-5 0-5 8 0-0 0 0-0 6 0-0 1 0-9 8 0-2 3 0-1 6 0-4 3 0-5 7 0-1 7 0-7 7 0-8 3 0-1 0 0-3 5 0-2 5 0-2 1 0-6 1 0-7 7 0-2 9 0-2 7 0-4 3 0-5 1 0-3 5 0-7 9 0-8 2 0-9 6 0-5 8 0-6 7 0-7 3 0-4 2 0-4 0 0-5 4 0-7 0 0-5 8 0-5 7 0-6 0 0-6 9 0-6 4 0-7 6 0-9 3 0-9 5 0-9 7 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 10/400 [00:05<03:53,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 7 0-2 7 0-0 7 0-0 4 0-0 5 0-0 7 0-0 4 0-8 8 0-0 5 0-2 0-3 0-3 7 0-4 5 0-5 8 0-6 8 0-7 9 0-1 1 0-1 6 0-3 4 0-2 8 0-5 6 0-2 2 0-7 4 0-2 4 0-2 9 0-4 2 0-3 6 0-6 8 0-7 2 0-8 7 0-3 4 0-4 8 0-4 8 0-4 8 0-8 3 0-4 3 0-6 6 0-7 9 0-5 9 0-5 0 0-6 9 0-8 1 0-9 0 0-8 4 0-9 9 0-8 9 0-9 9 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 11/400 [00:06<03:52,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 1 0-0 4 0-3 5 0-0 1 0-0 0 0-0 7 0-7 9 0-8 5 0-9 9 0-2 1 0-1 8 0-4 8 0-1 7 0-1 7 0-1 8 0-1 0-9 0-1 3 0-3 1 0-4 7 0-5 6 0-2 0 0-7 6 0-2 2 0-9 5 0-4 8 0-5 7 0-6 3 0-7 9 0-8 4 0-9 7 0-5 4 0-4 7 0-4 3 0-8 9 0-4 1 0-5 6 0-5 7 0-5 1 0-5 1 0-6 4 0-6 9 0-6 5 0-8 4 0-9 6 0-8 8 0-9 8 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 12/400 [00:07<03:51,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 0-7 0-0 1 0-0 6 0-0 8 0-0 7 0-6 2 0-7 9 0-0 8 0-9 8 0-2 6 0-1 5 0-4 4 0-1 7 0-6 4 0-7 2 0-1 6 0-9 5 0-2 3 0-2 3 0-5 2 0-6 0 0-7 9 0-8 5 0-9 3 0-4 1 0-3 0-8 0-6 7 0-7 7 0-8 3 0-9 0 0-4 1 0-6 6 0-4 9 0-4 3 0-9 6 0-6 9 0-5 0 0-5 7 0-5 7 0-7 6 0-6 8 0-6 0 0-7 4 0-9 7 0-9 1 0-9 1 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 13/400 [00:07<03:52,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 9 0-2 4 0-3 1 0-4 9 0-0 8 0-6 1 0-7 9 0-8 0 0-9 6 0-2 0 0-1 4 0-1 9 0-1 5 0-6 9 0-7 4 0-8 1 0-9 3 0-2 1 0-2 1 0-5 9 0-2 9 0-2 6 0-8 8 0-9 2 0-4 7 0-3 9 0-6 7 0-3 8 0-8 1 0-9 5 0-4 8 0-4 0 0-4 9 0-8 4 0-4 9 0-6 8 0-5 9 0-5 2 0-5 0 0-6 9 0-6 3 0-6 7 0-7 5 0-7 6 0-8 3 0-9 0 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 14/400 [00:08<03:55,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 3 0-2 4 0-0 4 0-4 8 0-0 9 0-6 1 0-0 9 0-0 8 0-9 3 0-2 6 0-1 4 0-1 6 0-5 5 0-6 9 0-1 9 0-8 8 0-9 1 0-2 2 0-4 2 0-2 7 0-2 1 0-7 7 0-8 6 0-9 9 0-4 2 0-5 9 0-3 9 0-3 9 0-8 2 0-9 8 0-4 7 0-4 7 0-4 3 0-4 2 0-4 9 0-5 4 0-5 8 0-5 7 0-5 6 0-6 4 0-6 7 0-6 0 0-8 9 0-9 2 0-9 1 0-9 1 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 15/400 [00:09<03:55,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 8 0-2 1 0-0 6 0-0 9 0-0 3 0-6 5 0-0 5 0-8 1 0-0 6 0-2 8 0-1 7 0-1 5 0-1 0 0-1 1 0-1 1 0-8 8 0-1 8 0-3 9 0-2 4 0-5 6 0-6 9 0-7 1 0-8 6 0-9 1 0-4 9 0-3 7 0-6 5 0-7 0 0-8 1 0-3 8 0-5 1 0-6 7 0-4 8 0-4 6 0-4 1 0-6 6 0-5 7 0-5 3 0-9 8 0-6 1 0-6 9 0-6 6 0-7 2 0-7 1 0-8 1 0-9 1 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 16/400 [00:09<03:53,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 1 0-0 5 0-0 3 0-4 9 0-5 0 0-0 5 0-7 1 0-8 6 0-9 9 0-2 2 0-1 0 0-4 6 0-1 0-8 0-1 2 0-1 6 0-8 6 0-1 8 0-2 8 0-2 6 0-5 4 0-2 8 0-2 2 0-2 9 0-9 3 0-4 3 0-5 9 0-6 6 0-7 1 0-8 1 0-9 2 0-5 2 0-6 2 0-4 4 0-4 7 0-9 9 0-6 2 0-7 0 0-5 2 0-9 7 0-6 1 0-6 9 0-9 9 0-8 6 0-9 8 0-8 5 0-9 5 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 17/400 [00:10<03:51,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 8 0-2 2 0-0 7 0-0 3 0-0 2 0-0 1 0-7 1 0-0 2 0-9 7 0-2 1 0-3 8 0-4 8 0-1 1 0-6 2 0-1 0 0-8 3 0-9 7 0-3 1 0-2 2 0-5 4 0-6 7 0-2 4 0-2 5 0-9 1 0-4 9 0-3 4 0-3 8 0-3 9 0-3 0 0-9 6 0-5 5 0-6 2 0-4 9 0-4 1 0-9 7 0-5 7 0-5 7 0-5 6 0-9 9 0-7 3 0-6 9 0-6 9 0-7 5 0-9 9 0-8 3 0-9 3 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 18/400 [00:10<03:49,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 7 0-2 1 0-0 1 0-0 9 0-0 7 0-0 1 0-0 9 0-0 6 0-0 6 0-1 2 0-1 5 0-4 6 0-1 6 0-6 6 0-1 0 0-1 6 0-1 1 0-3 7 0-2 5 0-2 5 0-6 5 0-7 4 0-2 3 0-9 5 0-3 5 0-3 3 0-3 6 0-3 9 0-3 6 0-3 9 0-5 2 0-4 5 0-4 3 0-4 4 0-4 8 0-5 2 0-5 4 0-5 8 0-5 5 0-6 4 0-6 8 0-6 9 0-7 9 0-9 7 0-9 1 0-9 1 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 19/400 [00:11<03:48,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 6 0-2 5 0-0 8 0-4 9 0-0 9 0-0 8 0-7 0 0-8 9 0-0 7 0-2 5 0-1 3 0-4 3 0-5 1 0-1 5 0-1 5 0-1 2 0-1 5 0-2 8 0-2 1 0-5 8 0-2 6 0-2 1 0-2 7 0-9 2 0-4 5 0-5 3 0-3 7 0-7 1 0-8 2 0-3 4 0-4 4 0-4 1 0-4 1 0-4 2 0-4 1 0-5 9 0-7 3 0-5 4 0-5 4 0-6 4 0-6 7 0-9 2 0-7 7 0-7 4 0-8 7 0-9 7 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 20/400 [00:12<03:49,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 0 0-2 8 0-0 4 0-4 5 0-5 5 0-0 8 0-7 2 0-0 8 0-9 7 0-2 3 0-1 9 0-4 0 0-5 0 0-6 6 0-1 6 0-1 3 0-9 1 0-3 4 0-2 0-5 0-2 1 0-2 6 0-2 3 0-8 9 0-9 1 0-4 7 0-3 7 0-6 0 0-7 7 0-3 3 0-9 8 0-5 8 0-6 1 0-7 8 0-4 1 0-9 3 0-6 1 0-5 5 0-5 4 0-9 0 0-6 8 0-6 5 0-6 3 0-7 2 0-9 7 0-8 3 0-9 3 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 21/400 [00:12<03:48,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 4 0-0 7 0-3 0-8 0-0 4 0-5 2 0-6 6 0-0 2 0-8 8 0-9 1 0-2 6 0-3 5 0-1 3 0-1 2 0-6 0 0-7 3 0-8 1 0-9 2 0-3 8 0-2 9 0-2 4 0-6 2 0-7 4 0-2 7 0-9 8 0-3 2 0-3 9 0-3 2 0-3 0 0-3 3 0-3 4 0-5 2 0-6 2 0-4 8 0-4 4 0-9 7 0-6 8 0-5 4 0-5 0 0-5 1 0-7 8 0-6 0 0-6 9 0-7 9 0-7 2 0-8 9 0-9 9 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 22/400 [00:13<03:46,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 9 0-0 4 0-0 9 0-4 4 0-0 1 0-6 2 0-7 1 0-8 9 0-9 2 0-2 0 0-3 1 0-4 6 0-5 7 0-6 1 0-7 5 0-8 9 0-9 1 0-2 1 0-4 6 0-5 0 0-2 5 0-7 8 0-2 7 0-9 9 0-4 9 0-3 6 0-6 2 0-7 8 0-8 2 0-9 6 0-5 3 0-6 5 0-7 3 0-8 9 0-9 2 0-5 1 0-5 0 0-5 6 0-9 9 0-6 9 0-6 2 0-9 0 0-7 4 0-7 8 0-9 8 0-9 8 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 23/400 [00:13<03:45,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 5 0-2 0 0-0 4 0-0 6 0-5 9 0-0 4 0-7 0 0-0 4 0-9 6 0-2 1 0-1 5 0-4 8 0-1 8 0-1 8 0-7 4 0-8 9 0-1 0 0-3 3 0-2 5 0-2 9 0-6 3 0-2 0 0-2 5 0-2 9 0-3 9 0-3 3 0-6 8 0-3 5 0-8 9 0-9 1 0-5 5 0-6 0-9 0-4 1 0-4 9 0-4 6 0-5 6 0-5 6 0-5 6 0-5 9 0-6 6 0-6 0 0-6 4 0-7 8 0-9 7 0-8 3 0-9 3 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 24/400 [00:14<03:45,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 8 0-2 0-3 0-0 9 0-0 0 0-5 0-8 0-6 0 0-7 8 0-0 8 0-0 7 0-2 9 0-1 9 0-1 6 0-1 1 0-6 9 0-7 9 0-8 7 0-1 6 0-3 8 0-2 1 0-2 3 0-2 1 0-2 9 0-8 7 0-9 6 0-4 7 0-3 3 0-6 8 0-7 2 0-3 3 0-3 6 0-4 2 0-6 8 0-4 6 0-4 9 0-9 5 0-5 0 0-5 8 0-5 4 0-5 7 0-7 6 0-6 4 0-6 3 0-7 4 0-9 1 0-8 7 0-9 7 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 25/400 [00:15<03:44,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 4 0-0 3 0-3 7 0-0 5 0-5 6 0-0 5 0-7 4 0-8 7 0-0 0 0-1 3 0-3 1 0-4 4 0-5 6 0-6 9 0-7 4 0-8 1 0-9 0 0-3 4 0-2 9 0-2 5 0-6 8 0-7 9 0-8 6 0-9 7 0-4 0 0-3 3 0-3 8 0-7 2 0-3 4 0-9 2 0-4 7 0-4 5 0-7 0 0-4 7 0-4 8 0-5 1 0-5 6 0-5 3 0-5 4 0-6 5 0-6 2 0-6 3 0-7 5 0-9 4 0-8 6 0-9 6 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 26/400 [00:15<03:43,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 2 0-0 6 0-3 7 0-0 6 0-5 2 0-0 7 0-7 6 0-8 9 0-9 7 0-2 6 0-1 9 0-1 6 0-1 5 0-6 9 0-1 2 0-1 5 0-1 7 0-3 1 0-2 0 0-5 9 0-6 1 0-7 6 0-2 7 0-9 0 0-3 3 0-3 7 0-6 4 0-3 0-8 0-8 0 0-9 8 0-4 5 0-6 6 0-4 9 0-4 9 0-9 0 0-6 5 0-5 5 0-8 1 0-5 7 0-6 7 0-6 0 0-6 2 0-7 8 0-9 6 0-8 6 0-9 6 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 27/400 [00:16<03:42,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 6 0-2 3 0-0 8 0-0 0 0-5 8 0-6 2 0-7 4 0-8 7 0-9 3 0-1 2 0-1 7 0-1 7 0-5 3 0-6 6 0-1 3 0-1 1 0-9 0 0-3 3 0-2 4 0-5 1 0-2 3 0-7 3 0-2 0 0-9 7 0-4 2 0-5 0-7 0-3 2 0-7 3 0-8 2 0-9 9 0-4 3 0-6 3 0-4 5 0-8 3 0-4 9 0-6 8 0-5 9 0-5 9 0-5 1 0-6 7 0-6 9 0-9 1 0-8 4 0-9 8 0-9 6 0-9 6 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 28/400 [00:16<03:42,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 8 0-2 8 0-0 9 0-4 6 0-0 2 0-6 1 0-7 2 0-0 1 0-9 9 0-1 8 0-1 3 0-1 6 0-1 2 0-1 6 0-7 2 0-1 8 0-9 9 0-3 8 0-2 5 0-2 2 0-2 1 0-7 2 0-2 2 0-9 6 0-4 9 0-3 0-9 0-3 4 0-3 0-9 0-8 2 0-9 2 0-5 0 0-6 6 0-4 8 0-4 7 0-4 7 0-5 2 0-5 6 0-5 1 0-5 7 0-6 2 0-6 5 0-6 7 0-8 1 0-9 1 0-9 6 0-9 9 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 29/400 [00:17<03:41,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 6 0-0 6 0-0 7 0-0 0-5 0-5 3 0-0 9 0-7 5 0-0 7 0-0 3 0-2 8 0-1 5 0-4 7 0-1 9 0-6 9 0-7 0 0-1 6 0-9 1 0-3 7 0-2 9 0-2 5 0-6 9 0-7 6 0-8 0 0-9 3 0-4 7 0-3 9 0-6 0 0-7 1 0-8 4 0-3 6 0-4 4 0-4 8 0-4 5 0-4 9 0-4 8 0-6 9 0-5 7 0-5 4 0-5 5 0-6 6 0-6 0 0-6 3 0-7 1 0-9 4 0-8 1 0-9 0 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 30/400 [00:18<03:41,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 0 0-2 6 0-0 0 0-4 1 0-0 0 0-6 4 0-7 0 0-8 4 0-9 6 0-2 4 0-1 8 0-1 0 0-1 8 0-6 9 0-1 5 0-1 8 0-9 5 0-3 7 0-2 6 0-5 0 0-2 5 0-7 0 0-2 4 0-9 1 0-4 1 0-3 1 0-6 6 0-3 8 0-8 2 0-9 4 0-5 6 0-6 3 0-7 9 0-4 0 0-9 5 0-6 3 0-5 9 0-8 4 0-5 5 0-6 2 0-6 9 0-6 0 0-7 8 0-9 4 0-9 4 0-9 4 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 31/400 [00:18<03:40,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 3 0-2 3 0-0 8 0-0 7 0-5 6 0-0 1 0-7 8 0-8 6 0-9 2 0-2 0 0-3 9 0-4 0-5 0-5 2 0-1 4 0-7 9 0-8 7 0-1 1 0-2 0 0-2 7 0-5 3 0-2 0 0-7 5 0-8 3 0-9 5 0-4 4 0-5 1 0-6 5 0-7 9 0-8 1 0-9 4 0-5 5 0-6 7 0-4 6 0-4 5 0-4 6 0-6 3 0-7 0 0-8 6 0-5 2 0-6 5 0-6 3 0-9 7 0-7 0 0-9 1 0-8 8 0-9 1 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 32/400 [00:19<03:39,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 8 0-2 9 0-0 4 0-4 8 0-5 2 0-6 3 0-0 8 0-8 6 0-9 7 0-1 9 0-1 8 0-4 9 0-5 9 0-1 9 0-1 7 0-8 2 0-9 1 0-3 9 0-2 7 0-5 7 0-2 9 0-7 3 0-2 9 0-9 1 0-4 6 0-3 7 0-6 0 0-3 0 0-3 5 0-9 9 0-5 2 0-6 3 0-4 8 0-4 7 0-9 8 0-6 9 0-7 4 0-5 7 0-9 7 0-6 9 0-6 8 0-9 8 0-8 7 0-9 7 0-8 2 0-9 2 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 33/400 [00:19<03:39,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 8 0-0 3 0-0 8 0-0 4 0-0 7 0-0 0 0-7 6 0-0 3 0-9 0 0-2 2 0-1 0 0-4 7 0-1 0 0-1 2 0-7 8 0-1 7 0-9 4 0-3 5 0-2 3 0-2 1 0-6 9 0-2 0 0-2 4 0-9 9 0-4 6 0-3 9 0-3 3 0-3 9 0-3 9 0-9 0 0-5 5 0-6 9 0-7 7 0-4 9 0-9 8 0-6 4 0-5 5 0-5 7 0-9 1 0-6 1 0-6 9 0-9 5 0-7 0 0-9 7 0-9 6 0-9 6 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 34/400 [00:20<03:38,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 0 0-2 5 0-3 1 0-0 9 0-5 5 0-6 7 0-0 8 0-8 6 0-9 7 0-2 5 0-1 7 0-4 6 0-5 9 0-1 7 0-1 4 0-1 2 0-9 3 0-3 7 0-2 8 0-2 4 0-2 2 0-2 7 0-2 4 0-9 2 0-4 7 0-3 4 0-6 0-7 0-3 5 0-8 7 0-3 4 0-4 8 0-6 3 0-7 4 0-4 8 0-4 2 0-6 2 0-5 1 0-5 4 0-5 8 0-7 5 0-6 1 0-6 0 0-7 0 0-7 1 0-9 7 0-9 7 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 35/400 [00:20<03:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 1 0-2 7 0-0 6 0-4 8 0-5 2 0-0 4 0-0 6 0-8 1 0-9 7 0-2 8 0-3 8 0-4 2 0-5 5 0-1 9 0-7 4 0-8 9 0-1 0 0-2 0 0-2 2 0-2 9 0-2 0-7 0-7 8 0-2 3 0-9 7 0-4 8 0-3 0 0-6 9 0-7 4 0-8 2 0-9 9 0-4 9 0-6 8 0-4 6 0-8 6 0-4 3 0-6 8 0-5 5 0-5 1 0-5 7 0-6 9 0-8 5 0-6 4 0-8 2 0-7 1 0-8 9 0-9 7 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 36/400 [00:21<03:38,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 4 0-0 5 0-0 5 0-4 2 0-0 4 0-0 1 0-7 2 0-8 6 0-9 4 0-2 9 0-3 8 0-4 5 0-1 8 0-6 7 0-1 7 0-8 2 0-9 7 0-3 9 0-2 1 0-2 9 0-2 8 0-7 9 0-2 3 0-2 2 0-4 9 0-5 9 0-6 4 0-7 9 0-8 3 0-9 4 0-4 0-8 0-4 1 0-4 8 0-4 0 0-9 1 0-5 5 0-5 9 0-5 2 0-5 0 0-6 5 0-6 9 0-9 0 0-7 0 0-9 4 0-8 2 0-9 2 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 37/400 [00:22<03:39,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 5 0-2 5 0-0 8 0-0 2 0-0 5 0-6 5 0-7 8 0-8 9 0-9 8 0-2 2 0-3 9 0-4 9 0-5 2 0-6 9 0-1 5 0-1 6 0-9 5 0-3 1 0-2 9 0-2 9 0-6 2 0-2 1 0-8 4 0-9 7 0-4 8 0-3 1 0-3 6 0-7 4 0-8 7 0-9 0 0-4 5 0-6 8 0-7 4 0-4 1 0-9 4 0-6 7 0-5 5 0-5 4 0-9 8 0-7 6 0-6 9 0-6 1 0-7 8 0-7 8 0-9 3 0-9 3 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 38/400 [00:22<03:38,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 6 0-0 1 0-0 9 0-4 0 0-0 2 0-0 5 0-7 3 0-8 1 0-0 1 0-2 0 0-3 8 0-4 8 0-1 1 0-1 6 0-7 4 0-1 3 0-9 2 0-3 8 0-2 9 0-2 9 0-2 5 0-7 0 0-2 0 0-9 2 0-4 5 0-3 0 0-6 0-9 0-3 2 0-3 8 0-3 7 0-5 1 0-4 4 0-4 2 0-4 1 0-9 3 0-5 6 0-7 9 0-5 4 0-5 3 0-6 9 0-6 5 0-9 7 0-8 7 0-9 6 0-9 2 0-9 2 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 39/400 [00:23<03:37,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 8 0-0 1 0-0 7 0-0 5 0-0 1 0-6 4 0-7 6 0-0 5 0-0 6 0-2 8 0-3 3 0-1 6 0-5 6 0-6 4 0-1 2 0-8 9 0-1 2 0-3 6 0-2 4 0-2 0 0-6 8 0-7 7 0-8 9 0-9 7 0-4 0 0-3 4 0-6 1 0-7 4 0-3 1 0-9 1 0-4 2 0-6 6 0-4 8 0-8 7 0-9 9 0-6 9 0-7 4 0-8 6 0-9 5 0-6 2 0-6 0-9 0-9 0 0-7 1 0-9 1 0-8 1 0-9 1 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 40/400 [00:24<03:36,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 8 0-2 8 0-0 1 0-4 5 0-0 4 0-6 7 0-0 4 0-8 7 0-0 9 0-1 8 0-3 5 0-4 0 0-5 8 0-6 9 0-1 1 0-1 0 0-9 3 0-2 5 0-2 9 0-5 8 0-6 4 0-7 8 0-8 9 0-9 7 0-4 2 0-5 9 0-6 4 0-7 1 0-8 5 0-9 5 0-5 8 0-4 6 0-4 1 0-4 6 0-4 5 0-6 6 0-5 4 0-5 4 0-9 4 0-6 9 0-6 1 0-6 2 0-7 6 0-7 1 0-9 0 0-9 0 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 41/400 [00:24<03:35,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 1 0-0 9 0-0 6 0-4 8 0-5 7 0-6 8 0-0 7 0-0 7 0-0 9 0-2 2 0-1 9 0-1 7 0-1 1 0-6 4 0-1 4 0-8 2 0-1 1 0-3 8 0-2 7 0-5 6 0-6 7 0-2 6 0-2 0 0-9 8 0-4 2 0-5 9 0-6 9 0-3 3 0-8 7 0-9 6 0-4 1 0-6 8 0-4 1 0-4 6 0-4 0 0-6 6 0-7 5 0-5 5 0-5 7 0-6 3 0-6 2 0-6 1 0-7 6 0-9 0 0-9 5 0-9 5 A False\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 42/400 [00:25<03:34,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 5 0-0 3 0-0 7 0-0 4 0-0 6 0-6 3 0-0 4 0-0 7 0-9 4 0-2 7 0-3 0-4 0-1 3 0-5 9 0-1 2 0-1 9 0-1 1 0-9 2 0-2 1 0-2 6 0-2 0 0-6 5 0-2 6 0-2 6 0-9 8 0-4 3 0-5 3 0-6 9 0-3 1 0-8 7 0-9 5 0-4 8 0-6 7 0-4 9 0-4 1 0-4 6 0-6 9 0-5 9 0-5 7 0-9 8 0-6 0 0-6 0 0-6 1 0-7 0 0-9 6 0-8 8 0-9 8 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 43/400 [00:25<03:33,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 2 0-2 0-7 0-3 2 0-0 6 0-0 3 0-6 9 0-7 8 0-0 2 0-9 7 0-2 1 0-3 2 0-1 6 0-1 1 0-1 8 0-7 3 0-1 0 0-9 1 0-3 3 0-4 7 0-2 7 0-6 3 0-7 4 0-2 1 0-2 8 0-4 7 0-5 5 0-6 9 0-7 8 0-8 9 0-9 7 0-5 3 0-4 3 0-4 6 0-8 2 0-4 4 0-5 3 0-5 0 0-8 5 0-5 9 0-7 5 0-6 2 0-9 3 0-7 7 0-7 3 0-8 8 0-9 3 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 44/400 [00:26<03:33,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-0 6 0-2 1 0-3 2 0-4 2 0-0 8 0-6 5 0-7 9 0-0 3 0-9 6 0-1 7 0-1 9 0-4 9 0-1 4 0-1 1 0-7 1 0-8 7 0-1 9 0-2 0-6 0-2 1 0-2 9 0-6 8 0-2 9 0-2 5 0-2 1 0-4 5 0-3 1 0-6 8 0-3 2 0-8 6 0-9 1 0-4 2 0-6 7 0-4 8 0-4 3 0-9 6 0-5 5 0-5 9 0-5 6 0-5 8 0-6 3 0-6 3 0-6 1 0-7 7 0-9 2 0-9 6 0-9 7 A True\n",
      "1th highest logit for h_out:\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 45/400 [00:27<03:32,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th highest logit for h_out:\n",
      "0-1 6 0-2 1 0-3 1 0-4 5 0-0 5 0-0 8 0-7 4 0-0 3 0-0 8 0-2 1 0-3 9 0-4 1 0-5 6 0-6 8 0-1 9 0-1 9 0-9 9 0-3 0-9 0-2 6 0-2 6 0-6 0 0-7 9 0-2 4 0-9 4 0-4 8 0-3 6 0-6 9 0-3 9 0-3 4 0-9 9 0-5 3 0-4 7 0-4 1 0-4 8 0-4 8 0-6 6 0-7 9 0-5 4 0-5 3 0-7 6 0-6 2 0-6 1 0-7 9 0-7 2 0-9 1 0-9 1 A True\n"
     ]
    }
   ],
   "source": [
    "results_df = []\n",
    "\n",
    "indices = random.sample(range(0, len(test_set) + 1), 400)\n",
    "\n",
    "for idx in tqdm(indices):\n",
    "    result = model.print_logit_progression(test_set[idx], rank=1,layer_number=4, input_length=11) # tuple-len + 'P'\n",
    "    result_skip = model.print_logit_progression(test_set[idx], rank=1, layer_number=4, skip_idx=3, input_length=11) # tuple-len + 'P'\n",
    "    for k,v in result_skip.items():\n",
    "        result[\"f{k}_skip\"] = v\n",
    "    results_df.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_multi_rank_logit_progression(model, test_set, n_ranks, n_samples=100):\n",
    "#     token_dict = []\n",
    "    \n",
    "#     for seq_idx in tqdm(range(n_samples)):\n",
    "#         entry = {}\n",
    "        \n",
    "#         # Add label\n",
    "#         entry[\"label\"] = model.decode_tensors(test_set[seq_idx]['labels']).replace(\"[MASK] \", \"\")\n",
    "        \n",
    "#         # Process for each rank\n",
    "#         for rank in range(1, n_ranks + 1):\n",
    "#             rank_result = model.print_logit_progression(test_set[seq_idx], rank=rank)\n",
    "            \n",
    "#             for k, v in rank_result.items():\n",
    "#                 entry[f\"r{rank}_{k}\"] = \"\".join(v).split(\"[EOS]\")[0]\n",
    "        \n",
    "#         token_dict.append(entry)\n",
    "    \n",
    "#     # Convert to DataFrame\n",
    "#     df = pd.DataFrame(token_dict)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# for col in result_df.columns.drop('label'):\n",
    "#     edit_distances[f'{col}_edit_distance'] = result_df.apply(lambda row: Levenshtein.distance(row['label'], row[col]), axis=1)\n",
    "\n",
    "# # Display the first few rows of the new DataFrame\n",
    "# print(edit_distances.head())\n",
    "\n",
    "# avg_distances = edit_distances.mean().sort_values(ascending=False)\n",
    "\n",
    "# # Create a DataFrame with the average distances\n",
    "# avg_distances_df = pd.DataFrame({\n",
    "#     'Column': avg_distances.index,\n",
    "#     'Average Edit Distance': avg_distances.values\n",
    "# })\n",
    "\n",
    "# # Display the average distances\n",
    "# print(\"Average Edit Distances:\")\n",
    "# print(avg_distances_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d82929f0b2a0bc732f0b4a7de66959930da3979fa54e053e3cc98d8b0f7a869f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
